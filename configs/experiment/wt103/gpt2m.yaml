# @package _global_
defaults:
  - /experiment/wt103/gpt2.yaml

model:
  config:
    n_embd: 1024
    n_head: 16
    n_layer: 24

datamodule:
  batch_size: 8  # Per GPU

train:
  optimizer:
    lr: 1.5e-4
