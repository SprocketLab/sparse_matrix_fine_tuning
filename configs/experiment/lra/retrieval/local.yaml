# @package _global_
defaults:
  - /experiment/lra/retrieval/transformer
  - override /model/attn_cfg: local

model:
  attn_cfg:
    attention_dropout: 0.1
    local_context: 256
  # It's important to use mean pooling and not CLS token, as the CLS token won't
  # be connected to tokens beyond the local context. We don't want to classify
  # based on just the first 32 characters.
  pooling_mode: MEAN
