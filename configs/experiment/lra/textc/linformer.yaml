# @package _global_
defaults:
  - /experiment/lra/textc/transformer
  - override /model/attn_cfg: linformer

model:
  attn_cfg:
    seq_len: ${eval:"${model.pos_encoding_cfg.max_len} + int('${model.pooling_mode}' == 'CLS')"}
    k: 64
    attention_dropout: 0.1
