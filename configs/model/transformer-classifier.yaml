defaults:
  - attn_cfg: full
_target_: src.models.transformer.TransformerClassifier
d_model: ???
activation: gelu
norm_first: True
batch_first: True
pooling_mode: CLS
embedding_cfg:
  _target_: torch.nn.Embedding
  # num_embeddings will be read programmatically from datamodule after it is setup
  embedding_dim: ${..d_model}
pos_encoding_cfg:
  _target_: src.models.modules.seq_common.PositionalEncoding
  dropout: ${..dropout}
